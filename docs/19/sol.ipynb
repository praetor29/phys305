{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Monte Carlo Methods II: Ising Model and Hopfield Network (Lab Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In 2024, the **Nobel Prize in Physics** was awarded to **John J. Hopfield** and **Geoffrey E. Hinton** for their pioneering work on neural networks.\n",
    "Their contributions have played a significant role in the development of modern artificial intelligence and computational models inspired by biological learning mechanisms.\n",
    "\n",
    "- **John J. Hopfield** introduced the Hopfield network, a type of recurrent neural network that models associative memory and collective computation in neural systems.\n",
    "- **Geoffrey E. Hinton** made significant advancements in deep learning, particularly in training deep neural networks through the backpropagation algorithm.\n",
    "\n",
    "Their research has had profound implications in artificial intelligence, neuroscience, and computational physics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Why Do Neural Networks Matter?\n",
    "\n",
    "Neural networks are now an essential part of many everyday technologies:\n",
    "\n",
    "- **Facial Recognition:** Used to unlock smartphones and enhance security.\n",
    "- **Chatbots:** Power customer service agents that interact with users.\n",
    "- **Voice Assistants:** Siri, Alexa, and Google Assistant rely on neural networks for speech recognition.\n",
    "- **Self-Driving Cars:** Autonomous vehicles process sensor data using deep learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Importance of This Discovery\n",
    "\n",
    "Neural networks have revolutionized multiple domains, including:\n",
    "- **Language Translation:** Real-time translation services are powered by deep learning models.\n",
    "- **Medical Diagnosis:** AI-assisted analysis of medical images improves diagnostic accuracy.\n",
    "- **Scientific Research:** AI-driven simulations enhance modeling in physics, chemistry, and biology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## The Ising Model\n",
    "\n",
    "To understand how Hopfield networks operate, we first introduce the **Ising model**.\n",
    "\n",
    "The **Ising model** is a mathematical model in statistical mechanics, introduced by Wilhelm Lenz in 1920 and solved for the one-dimensional case by his student Ernst Ising in 1925.\n",
    "The model was originally used to explain ferromagnetism, where magnetic materials exhibit spontaneous magnetization due to interactions between neighboring atomic spins.\n",
    "\n",
    "- Wilhelm Lenz conceived the model as a simplified representation of magnetic interactions in a lattice, where spins can either point \"up\" (+1) or \"down\" (-1).\n",
    "- Ernst Ising solved the one-dimensional version of the model in his doctoral thesis, showing that it did not exhibit phase transitionsâ€”a result that was surprising at the time.\n",
    "- Lars Onsager solved the two-dimensional version of the model in 1944, demonstrating that it undergoes a phase transition at a critical temperature, where spontaneous magnetization occurs.\n",
    "\n",
    "Since then, the Ising model has become one of the most widely studied models in statistical physics and beyond.\n",
    "Its applications extend not only to physics (such as in magnetism and lattice gases) but also to fields like biology (neural networks), computer science (optimization problems), and even sociology (modeling opinion dynamics).\n",
    "\n",
    "The **Metropolis algorithm** (1953) was developed for Monte Carlo simulations of systems like the Ising model, enabling the study of large, complex systems by simulating their thermal fluctuations and statistical properties.\n",
    "This method revolutionized computational physics and remains a powerful tool in many areas of research today."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Basic Idea\n",
    "\n",
    "- Consider a **grid (lattice)** where each point represents a **spin**.\n",
    "- Each spin can take one of two states: **up (+1) or down (-1)**.\n",
    "- Spins interact with their neighbors, aiming to align in a way that minimizes system energy.\n",
    "- The system's **energy parameter** determines the likelihood of spins flipping, making temperature a crucial factor in system behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Let's start programming as we introduce the different concepts.\n",
    "Here, we create a python class to keep track of the state and temperature of an Ising Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass a numpy array to store the state of an Ising Model\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "\n",
    "class Ising(np.ndarray):\n",
    "\n",
    "    def __new__(cls, shape=(64,64), kT=1, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        obj = np.random.choice([-1,1], size=shape).view(cls)\n",
    "        obj.kT = kT\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        if obj is None: return\n",
    "        self.kT = getattr(obj, 'kT', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "With the class `Ising`, we can now instanize a Ising model by creating a 2D grid of spin state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: instanize a Ising model by creating a 2D grid of spin state.\n",
    "\n",
    "ising = Ising(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We can visualize the spin state by plotting `ising` as an image with `plt.imshow()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: visualize the spin state by plotting the state as an image\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(ising)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Interaction and Energy Minimization\n",
    "\n",
    "- The system's total energy is determined by how well-aligned the spins are with their neighbors.\n",
    "- At **high temperatures**, spins flip frequently due to thermal fluctuations, leading to disorder.\n",
    "- At **low temperatures**, spins align into ordered configurations, exhibiting phase transitions similar to those in magnetic materials.\n",
    "- The **Hamiltonian** (energy function) for the Ising model is:\n",
    "  \\begin{align}\n",
    "  H = - \\sum_{i,j} J_{ij} s_i s_j\n",
    "  \\end{align}\n",
    "  where:\n",
    "  - $s_i$ represents the spin at site $i$.\n",
    "  - $J_{ij}$ is the coupling strength between neighboring spins.\n",
    "- The system evolves dynamically to minimize $H$, leading to patterns of stable configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Energy Change Due to Spin Flip\n",
    "\n",
    "When a single spin $s_i$ flips, the change in energy is calculated by comparing the energy before and after the flip.\n",
    "The energy difference $\\Delta E$ due to flipping the spin at site $i$ is:\n",
    "\\begin{align}\n",
    "\\Delta E = 2 s_i \\sum_{j} J_{ij} s_j,\n",
    "\\end{align}\n",
    "where the sum is over the nearest neighbors $j$ of site $i$.\n",
    "The factor of 2 arises because flipping the spin at site $i$ changes its contribution to the energy from $-s_i s_j$ to $+s_i s_j$.\n",
    "\n",
    "Choose $J_{ij}$ so that only neighborhood cells have interaction 1, we can implement the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please implement the following function according to the above equation\n",
    "\n",
    "def energy_change(ising, i, j):\n",
    "    I, J = ising.shape  # Get lattice dimensions\n",
    "    spin = ising[i, j]  # Current spin value\n",
    "    \n",
    "    # Neighboring spins (periodic boundary conditions)\n",
    "    neighbors = (  ising[(i+1)%I, j] \n",
    "                 + ising[(i-1)%I, j]\n",
    "                 + ising[i, (j+1)%J]\n",
    "                 + ising[i, (j-1)%J])\n",
    "\n",
    "    # Energy difference due to spin flip\n",
    "    return 2 * spin * neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "We may now obtain the energy change for flipping a spin at different cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: choose different i and j and compute the energy change by calling `energy_change(state, i, j)`\n",
    "\n",
    "energy_change(ising, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Metropolis Algorithm\n",
    "\n",
    "To simulate the evolution of the system at a given temperature, we use the Metropolis algorithm.\n",
    "This algorithm probabilistically accepts or rejects a spin flip based on the energy change $\\Delta E$ and the temperature $T$.\n",
    "The probability of accepting a spin flip is given by the Boltzmann factor:\n",
    "\\begin{align}\n",
    "P(\\text{flip}) =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } \\Delta E < 0, \\\\\n",
    "\\exp\\left(-\\frac{\\Delta E}{k T}\\right) & \\text{if } \\Delta E \\geq 0,\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "where:\n",
    "- $\\Delta E$ is the energy change caused by the flip.\n",
    "- $k$ is the Boltzmann constant.\n",
    " $T$ is the temperature.\n",
    "\n",
    "This allows the system to \"explore\" higher energy states at higher temperatures (thermal fluctuations), while favoring low-energy configurations as the system cools down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "We can implement a function `flip(ising, i, j)` to determent if we need to flip the spin `ising` at grid `i`, `j`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please implement the following function according to the above equation\n",
    "\n",
    "def flip(ising, i, j):\n",
    "    dE = energy_change(ising, i, j)  # Compute energy change\n",
    "    \n",
    "    if dE < 0:  # Check the sign of energy change\n",
    "        return True  # Always accept flip if energy decreases\n",
    "    else:\n",
    "        return np.random.rand() < np.exp(-dE / ising.kT)  # Accept flip with Boltzmann probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Note the `np.random.rand()` function in `flip()`.\n",
    "Choose a cell with positive energy change and run flip multiple times.\n",
    "What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: try repeat flip() many times\n",
    "\n",
    "np.array([flip(ising, 1, 1) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "What happen if you change the temperature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: try change `kT` and then repeat flip()\n",
    "\n",
    "ising1 = Ising(kT=10, seed=42)\n",
    "print(np.array([flip(ising1, 1, 1) for _ in range(100)]))\n",
    "\n",
    "ising2 = Ising(kT=0.1, seed=42)\n",
    "print(np.array([flip(ising2, 1, 1) for _ in range(100)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "With the above helper functions, we are ready to implement the Ising Model using the metropolis algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please implement the following function according to the metropolis algorithm\n",
    "\n",
    "def run(ising, N=100):\n",
    "    for _ in range(N):  # Repeat the simulation N times\n",
    "        i = randint(0, ising.shape[0])  # Random row index\n",
    "        j = randint(0, ising.shape[1])  # Random column index\n",
    "        if flip(ising, i, j):  # Check if we need to flip the spin\n",
    "            ising[i, j] *= -1  # Actually flip the spin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "That's it!\n",
    "We can how compare the spin state before and after running the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: visualize the initial spin state\n",
    "\n",
    "plt.imshow(ising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: run the simuluation for, e.g., 100,000 steps\n",
    "\n",
    "run(ising, 100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: ... and then visualize the final spin state\n",
    "\n",
    "plt.imshow(ising)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Animate the Ising Model\n",
    "\n",
    "Just for fun, let's definte the following helper function to create animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define `animate(state, Nsub=100, N=250)` to create animation\n",
    "\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def animate(state, update, nsub=100, n=250, cmap='viridis'):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
    "    im = ax.imshow(state, cmap=cmap)\n",
    "    def func(i):\n",
    "        update(state, nsub)\n",
    "        im.set_array(state)\n",
    "        return [im]\n",
    "    an = FuncAnimation(fig, func, frames=n, interval=40, blit=True)\n",
    "    plt.close()\n",
    "    return an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: use the animate(state, update, nsub, n) to create an animation object `an`\n",
    "\n",
    "ising = Ising()\n",
    "an = animate(ising, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: show the animation object as a video using HTML()\n",
    "\n",
    "HTML(an.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Measuring Magnetization\n",
    "\n",
    "Physically, magnetization measures the net magnetic moment of the system.\n",
    "In the 2D Ising model, each spin contributes either +1 or -1.\n",
    "The total magnetization is simply the sum of all spins $M = \\sum_i s_i$.\n",
    "\n",
    "We often normalize the magnetization by dividing by the total number of spins to get a value between -1 and 1:\n",
    "\\begin{align}\n",
    "m = \\frac{1}{N} \\sum_i s_i\n",
    "\\end{align}\n",
    "* If all spins are aligned up, $m = 1$.\n",
    "* If all spins are aligned down, $m = -1$.\n",
    "* If spins are randomized, $m \\approx 0$.\n",
    "\n",
    "This normalized magnetization tells us how \"ordered\" the system is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please implement the following function according to the above equation\n",
    "\n",
    "def mag(ising):\n",
    "    return np.sum(ising) / ising.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "With this, we can plot the magnetization as function of, e.g., every 1000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: plot magnetization, i.e., as a function of every 1000 steps for 1000_000 steps in total\n",
    "\n",
    "ising = Ising()\n",
    "\n",
    "ms = []\n",
    "for _ in range(1000):\n",
    "    run(ising, 100)\n",
    "    ms.append(mag(ising))\n",
    "\n",
    "plt.plot(ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "### Phase Transition\n",
    "\n",
    "The Ising model is important because it is the simplest model that shows phase transition.\n",
    "The temperature `kT` is the parameter that control the phase.\n",
    "* At high temperature, thermal fluctuations dominate: the system becomes disordered and $m \\approx 0$.\n",
    "* At low temperature, the system settles into an ordered state: $m \\approx \\pm1$.\n",
    "* Near a critical temperature T_c, the system undergoes a phase transition from disordered to ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: Let's implementat a function that takes the temperature\n",
    "# of an Ising model and returns a list of magnetization\n",
    "\n",
    "def getmag(kT):\n",
    "    ising = Ising(kT=kT)\n",
    "\n",
    "    ms = []\n",
    "    for _ in range(1000):\n",
    "        run(ising, 100)\n",
    "        ms.append(mag(ising))\n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: We can now use getmag(kT) to run numerical experiments.\n",
    "# First, let's run getmag() and plot the history 10 times for the same temperature.\n",
    "# You may use the `tqdm` package to obtain a process bar.\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    ms = getmag(1)\n",
    "    plt.plot(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: Next, let's run getmag() and plot the history 10 times for different temperature\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for kT in tqdm(np.logspace(-1,1,11)):\n",
    "    ms = getmag(kT)\n",
    "    plt.plot(ms, label=f'kT={kT:.2f}')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "You should observe see the magnetization evolves very differently above critical temperature $k T_c \\approx 2.27$, which indicates a phase transition.\n",
    "To make it easier to see, one may plot just the absolute value of the last point of the histories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: Let's only plot the absolute value of the last point of the histories\n",
    "\n",
    "kTs = np.logspace(-1,1,11)\n",
    "ms  = [abs(getmag(kT)[-1]) for kT in tqdm(kTs)]\n",
    "plt.plot(kTs, ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "The above plot is a bit noise...  Let's average 10 realizations per temperature:}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: Let's average 10 realizations\n",
    "\n",
    "ms = [np.mean([abs(getmag(kT)[-1]) for _ in range(10)]) for kT in tqdm(kTs)]\n",
    "plt.plot(kTs, ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "Phase transition is one of the most striking features of the 2D Ising model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "## Hopfield Networks\n",
    "\n",
    "The **Hopfield network**, introduced by **John Hopfield in 1982**, is a recurrent neural network that stores and recalls patterns through energy minimization.\n",
    "\n",
    "- **Pattern Storage and Recall:** The network can store multiple patterns as stable configurations.\n",
    "- **Robustness to Noise:** If an input is noisy or incomplete, the network still retrieves the correct stored pattern.\n",
    "- **Content-Addressable Memory:** Unlike conventional memory, which retrieves data using addresses, Hopfield networks retrieve patterns based on similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "### Energy Landscape\n",
    "\n",
    "The Hopfield network shares deep similarities with the Ising model:\n",
    "- **Neurons replace spins**, taking binary values $+1$ or $-1$.\n",
    "- **Connections between neurons** correspond to interactions between spins.\n",
    "- **The system evolves toward stable, low-energy states**, just like in the Ising model.\n",
    "- **Both exhibit emergent global order** despite being governed by local interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "The energy function of the Hopfield network is given by:\n",
    "\\begin{align}\n",
    "E = - \\sum_{i,j} W_{ij} \\sigma_i \\sigma_j,\n",
    "\\end{align}\n",
    "where $W_{ij}$ represents synaptic weights and $\\sigma_i$ is the neuron state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "When a neuron updates, its **energy change** follows:\n",
    "\\begin{align}\n",
    "\\Delta E = 2 \\sigma_i \\sum_j W_{ij} \\sigma_j.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Why It Matters\n",
    "\n",
    "The Hopfield network played a **foundational role in artificial intelligence** by introducing energy-based models:\n",
    "- Inspired later developments such as **Boltzmann machines** and **Deep Learning architectures**.\n",
    "- Showed how memory and pattern recognition could emerge from simple neuron interactions.\n",
    "- Provided insights into **biological neural networks**, helping us understand how the brain processes and retrieves information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "Because of the similar between a Hopfield network and Ising model, similar, we subclass a numpy array to store the state of a Hopfield network.\n",
    "Instead of keeping track of the model's temperature `kT`, we create an empty array `W` to store the synaptic weights.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclass a numpy array to store the state of a Hopfield network\n",
    "\n",
    "class Hopfield(np.ndarray):\n",
    "\n",
    "    def __new__(cls, shape=(64,64), seed=None):\n",
    "        N = shape[0] * shape[1]\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        obj   = np.random.choice([-1,1], size=shape).view(cls)\n",
    "        obj.W = np.zeros((N, N))\n",
    "        return obj\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        if obj is None: return\n",
    "        self.W = getattr(obj, 'W', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "By default, an instance of the Hopfield class is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: instanize a Hopfield network and visualize its initial random state\n",
    "\n",
    "hopfield = Hopfield()\n",
    "plt.imshow(hopfield, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "### Hebbian Learning Rule\n",
    "\n",
    "The weights in a Hopfield network are learned using the Hebbian learning rule, which strengthens the connections between neurons that are activated together.\n",
    "It is given by:\n",
    "$$\n",
    "W_{ij} = \\frac{1}{P} \\sum_p \\sigma_i^{(p)} \\sigma_j^{(p)}.\n",
    "$$\n",
    "Where:\n",
    "* $N$ is the number of neurons.\n",
    "* $P$ is the number of patterns.\n",
    "* $\\sigma_i^{(p)}$ is the state of neuron $i$ in a pattern $p$.\n",
    "\n",
    "This makes Hopfield networks **powerful for associative memory**, allowing pattern retrieval even with noise.\n",
    "\n",
    "Using `numpy`'s function, it is straightforward to implement Hebbian's learning rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please implement the following function according to the above equation\n",
    "\n",
    "def learn(hopfield, patterns):\n",
    "    for pattern in patterns:  # Hopfield network can learn multiple patterns\n",
    "        assert pattern.shape == hopfield.shape  # Ensure pattern shape matches the state shape\n",
    "        p = pattern.flatten()\n",
    "        hopfield.W += np.outer(p, p)  # The Hebbian Learning Rule is mathematically an outer product\n",
    "        \n",
    "    np.fill_diagonal(hopfield.W, 0)  # Ensure no neuron connects to itself\n",
    "    hopfield.W /= len(patterns)      # Normalize by the number of patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "To test it out, let's download some sample images and read them into this notebook.\n",
    "Because downloading images does not affect our understanding of Hopfield network, let's just run the following code cells directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images from GitHub in case this notebook is opened in Google colab\n",
    "\n",
    "url  = \"https://raw.githubusercontent.com/rndsrc/2024_nobel-phys_hs/refs/heads/main/images/\"\n",
    "url1 = url + \"AI.jpg\"\n",
    "url2 = url + \"cloud.jpg\"\n",
    "url3 = url + \"computer.jpg\"\n",
    "\n",
    "! if [ ! -d images ]; then mkdir images && cd images && wget {url1} && wget {url2} && wget {url3}; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to read images\n",
    "\n",
    "from matplotlib import image as img\n",
    "\n",
    "def load(filename):\n",
    "    im = img.imread(filename)\n",
    "    if im.ndim == 3:\n",
    "        im = np.mean(im, axis=-1)   # Convert to grayscale if needed\n",
    "    im = np.where(im < 128, -1, 1)  # Convert grayscale to binary (-1, 1)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and display them\n",
    "\n",
    "im1 = load(\"images/AI.jpg\")\n",
    "im2 = load(\"images/cloud.jpg\")\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.imshow(im1, cmap='gray')\n",
    "ax0.set_title('Pattern \"AI\"')\n",
    "ax1.imshow(im2, cmap='gray')\n",
    "ax1.set_title('Pattern \"cloud\"')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "With these sample images, let's make our Hopfield network learn from these patterns.\n",
    "Note that the state of the Hopfield network has not change.\n",
    "It is still random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: check what happen to the Hopfield state after learning the patterns\n",
    "\n",
    "learn(hopfield, [im1, im2])\n",
    "plt.imshow(hopfield, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "Once the patterns are learn, we can recall each pixel value by:\n",
    "\\begin{align}\n",
    "  \\sigma_i^{(p)} = \\text{sgn}\\left(\\sum_j W_{ij} \\sigma_j^{(p)}\\right)\n",
    "\\end{align}\n",
    "which can be implemented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: please implement the following function according to the above equation\n",
    "\n",
    "def recall(hopfield, N):\n",
    "    for _ in range(N):\n",
    "        i = randint(0, hopfield.shape[0])  # Random row index\n",
    "        j = randint(0, hopfield.shape[1])  # Random column index\n",
    "        \n",
    "        # Update a single pixel in the pattern\n",
    "        index = i * hopfield.shape[1] + j\n",
    "        hopfield[i, j] = np.sign(np.dot(hopfield.W[index], hopfield.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "That's it!\n",
    "We've implemented all the functions of the Hopfield network!\n",
    "We can \"recall\" its memory and visulize the result by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: recall a pattern and visualize the result\n",
    "\n",
    "recall(hopfield, 100_000)\n",
    "plt.imshow(hopfield, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### Animate the Hopfield Network\n",
    "\n",
    "Just for fun again, we can now combine the implemented Hopfield network with the `animate(state, update, nsub, n)` helper function that we defined at the very beginning.\n",
    "\n",
    "The `recall()` function that we implemented actually has the same call signature as the `update()` function.\n",
    "Hence, we can use it to create the animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: animate memory recall of a Hopfield network\n",
    "\n",
    "hopfield = Hopfield()\n",
    "learn(hopfield, [im1, im2])\n",
    "an = animate(hopfield, recall, cmap='gray')\n",
    "HTML(an.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "This notebook has demonstrated how concepts from physics and AI intersect through models like the Ising Model and Hopfield Networks. Here are some questions to encourage further exploration:\n",
    "\n",
    "How do energy minimization principles in physics apply to AI and machine learning?\n",
    "Can you think of other real-world phenomena that could be modeled using energy-based systems?\n",
    "How might AI benefit from further insights from statistical mechanics and physics?\n",
    "What improvements could be made to the Hopfield Network to make it more efficient?\n",
    "For further study, students can explore more advanced models such as Boltzmann Machines, Restricted Boltzmann Networks, and Deep Learning frameworks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
