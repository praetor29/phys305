{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ODE Integrators III: Advanced Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Adaptive Stepsize Control\n",
    "\n",
    "When we integrate ordinary differential equations (ODEs), the choice of time step $\\Delta t$ can influence the accuracy and efficiency of our numerical solutions.\n",
    "This issue becomes especially important for systems that exhibit rapid changes in time and/or chaotic behavior.\n",
    "In such cases, tiny differences in initial conditions or time step selection can lead to wildly different outcomes.\n",
    "This highlights why we must continually monitor and control numerical errors.\n",
    "\n",
    "**Adaptive step size control** provides a systematic way to handle these challenges.\n",
    "Instead of using a fixed $\\Delta t$, adaptive methods dynamically change the time step based on error estimates at each step.\n",
    "The critical idea behind adaptive step size control is to balance two competing goals:\n",
    "* **Accuracy:** Keep truncation (local) errors within a user-specified tolerance.\n",
    "* **Efficiency:** Avoid making the time step too small, which would waste computational resources.\n",
    "\n",
    "In practice, we estimate the local error of a proposed step and compare it to a tolerance that combines both absolute and relative components.\n",
    "If the error is too large, we reduce the step size.\n",
    "If it is safely below the tolerance, we may increase it.\n",
    "This approach automatically \"zooms in\" when the ODE solution changes rapidly and \"zooms out\" when the solution is smoother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Error Estimate\n",
    "\n",
    "To illustrate one of the simplest ways to estimate errors, consider advancing the solution from $t$ to $t + 2\\Delta t$.\n",
    "There are two ways to do this:\n",
    "1. Step the ODE system with a single step $\\Delta t' = 2\\Delta t$.\n",
    "2. Step the ODE system with two consecutive steps, each step is $\\Delta t$.\n",
    "\n",
    "For a fourth-order method (e.g., classic Runge–Kutta 4), the local truncation errors differ between these two approaches.\n",
    "Symbolically, the resulting solutions (ignoring higher-order terms) look like:\n",
    "\\begin{align}\n",
    "\\text{One step:}  \\quad x(t + 2\\Delta t) &= x_1 + (2\\Delta t)^5 \\phi + \\mathcal{O}(\\Delta t^6) + \\dots \\\\\n",
    "\\text{Two steps:} \\quad x(t + 2\\Delta t) &= x_2 +  2\\Delta t^5  \\phi + \\mathcal{O}(\\Delta t^6) + \\dots\n",
    "\\end{align}\n",
    "where $\\phi$ is some function of $t$ and $x(t)$.\n",
    "We focus on just the leading $\\Delta t^5$ terms and define\n",
    "\\begin{align}\n",
    "\\Delta = x_2 - x_1,\n",
    "\\end{align}\n",
    "to give an approximate measure of the local truncation error.\n",
    "If $\\Delta$ is \"too large,\" we should reduce $\\Delta t$.\n",
    "If $\\Delta$ is \"too small,\" we might be over-resolving the solution and can safely increase $\\Delta t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Richardson Extrapolation\n",
    "\n",
    "An interesting by-product of step doubling is Richardson extrapolation, which can yield a higher-order estimate:\n",
    "\\begin{align}\n",
    "x(t + 2\\Delta t) = x_2 + \\frac{\\Delta}{15} + \\mathcal{O}(\\Delta t^6)\n",
    "\\end{align}\n",
    "While this estimate is more accurate (fifth-order), we have no direct way to estimate or control its truncation error at that higher order.\n",
    "Therefore, it is not as convenient for adaptive step size selection as one might initially hope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Embedded Runge-Kutta Formulas: The Dormand–Prince Method\n",
    "\n",
    "Although step doubling is an intuitive idea, modern ODE solvers usually rely on embedded Runge–Kutta formulas.\n",
    "An embedded method computes two solutions of different orders at each step without performing two full sets of time steps.\n",
    "\n",
    "Dormand–Prince (DP) methods belong to the family of Runge–Kutta integrators.\n",
    "For many practical problems, DP45 (also called “DOPRI5”) reaches a favorable balance between:\n",
    "* Accuracy per function evaluation\n",
    "* Reliability of its built-in error estimate\n",
    "* Simplicity of implementation\n",
    "\n",
    "For instance, Dormand–Prince 4(5) computes a fifth-order ($p=5$) approximation and a fourth-order ($p-1=4$) approximation simultaneously using only six function evaluations.\n",
    "It is popularity in libraries such as MATLAB's `ode45`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Below is the general structure of a 5th-order Runge–Kutta method:\n",
    "\\begin{align}\n",
    "k_1 &= \\Delta t\\,f(x_n, t_n)\\\\\n",
    "k_2 &= \\Delta t\\,f(x_n + a_{21}k_1, t_n + c_2 \\Delta t)\\\\\n",
    "\\cdots\\\\\n",
    "k_6 &= \\Delta t\\,f(x_n + a_{61}k_1 + \\cdots + a_{65}k_5, t_n + c_6 \\Delta t)\\\\\n",
    "x_{n+1} &= x_n + b_1 k_1 + b_2 k_2 + \\cdots + b_6 k_6 + \\mathcal{O}(\\Delta t^6)\n",
    "\\end{align}\n",
    "\n",
    "Dormand–Prince uses a particular set of coefficients $a_{ij}, b_i, c_i$.\n",
    "During each step, it also computes a lower-order approximation $x_\\text{low}$ using a different set $\\widetilde{b}_i$.\n",
    "The difference $x_\\text{high} - x_\\text{low}$ is used to estimate the local truncation error.\n",
    "\n",
    "Below are the coefficients for the DP method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[\n",
    "    [],\n",
    "    [1/5],\n",
    "    [3/40, 9/40],\n",
    "    [44/45, -56/15, 32/9],\n",
    "    [19372/6561, -25360/2187, 64448/6561, -212/729],\n",
    "    [9017/3168, -355/33, 46732/5247, 49/176, -5103/18656],\n",
    "    [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84],\n",
    "]\n",
    "\n",
    "b_high = [35/384, 0, 500/1113, 125/192, -2187/6784, 11/84, 0] # Fifth-order accurate solution estimate\n",
    "b_low  = [5179/57600, 0, 7571/16695, 393/640, -92097/339200, 187/2100, 1/40] # Fourth-order accurate solution estimate\n",
    "\n",
    "c = [0, 1/5, 3/10, 4/5, 8/9, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "A DP45 step is therefore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP45_step(f, x, t, dt):\n",
    "    # Compute intermediate k1 to k7\n",
    "    k1 = f(x)\n",
    "    k2 = f(x + dt*(a[1][0]*k1))\n",
    "    k3 = f(x + dt*(a[2][0]*k1 + a[2][1]*k2))\n",
    "    k4 = f(x + dt*(a[3][0]*k1 + a[3][1]*k2 + a[3][2]*k3))\n",
    "    k5 = f(x + dt*(a[4][0]*k1 + a[4][1]*k2 + a[4][2]*k3 + a[4][3]*k4))\n",
    "    k6 = f(x + dt*(a[5][0]*k1 + a[5][1]*k2 + a[5][2]*k3 + a[5][3]*k4 + a[5][4]*k5))\n",
    "    k7 = f(x + dt*(a[6][0]*k1 + a[6][1]*k2 + a[6][2]*k3 + a[6][3]*k4 + a[6][4]*k5 + a[6][5]*k6))\n",
    "\n",
    "    ks = [k1, k2, k3, k4, k5, k6, k7]\n",
    "\n",
    "    # Compute high and low order estimates\n",
    "    x_high = x\n",
    "    for b, k in zip(b_high, ks):\n",
    "        x_high += dt * b * k\n",
    "\n",
    "    x_low  = x \n",
    "    for b, k in zip(b_low, ks):\n",
    "        x_low += dt * b * k\n",
    "\n",
    "    return x_high, x_low, ks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Proportional-Integral (PI) Step Size Control\n",
    "\n",
    "Once we have an embedded Runge-Kutta method like Dormand–Prince in place, the next step is to implement a mechanism to adjust the step size based on the estimated local error.\n",
    "The PI (Proportional-Integral) controller is a widely-used strategy for this purpose, combining proportional and integral components to achieve stable and efficient step size adjustments.\n",
    "\n",
    "To decide if the step is \"acceptable,\" we compare the difference $| x_\\text{high} - x_\\text{low} |$ against a user-defined tolerance.\n",
    "A common practice is to combine an absolute tolerance (`atol`) for small values of the solution and a relative tolerance (`rtol`) for large ones.\n",
    "We form:\n",
    "\\begin{align}\n",
    "\\text{tol} = \\text{atol} + \\text{rtol}\\,|x_\\text{high}|.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "If the difference $|x_\\text{high} - x_\\text{low}|$ is larger than `tol`, we reject the step and try again with a smaller $\\Delta t$.\n",
    "If it is smaller, we accept the step, move forward in time, and possibly increase $\\Delta t$ for the next step.\n",
    "\n",
    "A widely used formula for updating $\\Delta t$ is:\n",
    "\\begin{align}\n",
    "h_{\\text{new}} = h \\cdot \\min\\left(\\text{fac}{\\text{max}}, \\max\\left(\\text{fac}{\\text{min}}, \\text{fac} \\cdot \\left(\\frac{\\text{tol}}{E}\\right)^{\\alpha}\\right)\\right)\n",
    "\\end{align}\n",
    "where\n",
    "* $\\text{fac}$ is a scaling factor (typically around 0.9) to provide a safety margin;\n",
    "* $\\text{fac}{\\text{min}}$ and $\\text{fac}{\\text{max}}$ set the minimum and maximum allowable step size multipliers to prevent excessive changes; and\n",
    "* $\\alpha$ is an exponent that determines the responsiveness of the step size adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Here is a simple Python function implementing this logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_update(dt, error, tol, fac=0.9, fac_min=0.1, fac_max=4.0, alpha=0.2):\n",
    "    if error == 0:\n",
    "        s = fac_max\n",
    "    else:\n",
    "        s = fac * (tol / error) ** alpha\n",
    "    s = min(fac_max, max(fac_min, s))\n",
    "    dt_new = dt * s\n",
    "    return dt_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Combining Steps and Control\n",
    "\n",
    "Putting it all together, we implement a basic DP45 integrator with adaptive step sizing.\n",
    "Notice that we allow the step to be reduced if the local error exceeds the tolerance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP45(f, x, t, T, dt, atol, rtol):\n",
    "\n",
    "    Ts = [t]\n",
    "    Xs = [np.array(x)]\n",
    "\n",
    "    while t < T:\n",
    "        if t + dt > T:\n",
    "            dt = T - t  # Adjust step size to end exactly at tf\n",
    "\n",
    "        # Perform a single Dormand–Prince step\n",
    "        x_high, x_low, _ = DP45_step(f, x, t, dt)\n",
    "\n",
    "        # Compute the error estimate\n",
    "        error = np.linalg.norm(x_high - x_low, ord=np.inf)\n",
    "\n",
    "        # Compute the tolerance\n",
    "        tol = atol + rtol * np.linalg.norm(x_high, ord=np.inf)\n",
    "\n",
    "        # Check if the step is acceptable\n",
    "        if error <= tol:\n",
    "            # Accept the step\n",
    "            t += dt\n",
    "            x = x_high\n",
    "            Ts.append(t)\n",
    "            Xs.append(x)\n",
    "\n",
    "        # Compute the new step size\n",
    "        dt = dt_update(dt, error, tol)\n",
    "\n",
    "    return np.array(Ts), np.array(Xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Example Applications\n",
    "\n",
    "We can now apply DP45 to integrate ODEs.\n",
    "\n",
    "Applying to the simple harmonic oscillator, we may specifically ask for the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_sh(x):\n",
    "    theta, omega = x\n",
    "    return np.array([omega, -theta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def error_DP45(tol):\n",
    "    T, X = DP45(f_sh, np.array([0, 0.01]), 0, 10, 0.1, tol, tol)\n",
    "    Theta  = X[:,0]\n",
    "    Thetap = 0.01 * np.sin(T)\n",
    "    return np.max(abs(Theta - Thetap))\n",
    "\n",
    "N     = np.array([64, 128, 256, 512, 1024])\n",
    "EDP45 = np.array([error_DP45(tol) for tol in 2.0**(-22-4*np.arange(5))])\n",
    "\n",
    "plt.loglog(N, 1/N**4,      label='1/N^4')\n",
    "plt.loglog(N, EDP45, 'o--', label='RK38')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel(r'$\\text{err} = max|x_\\text{numeric} - x|$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "For non-linear problems, we can also compare different accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_dp(x):\n",
    "    th1, th2, p1, p2 = x\n",
    "    \n",
    "    m  = 1\n",
    "    l  = 1\n",
    "    g  = 1\n",
    "\n",
    "    u1 = m * l * l\n",
    "    u2 = g / l\n",
    "    f  = 6 / (u1 * (16 - 9 * np.cos(th1 - th2)**2))\n",
    "\n",
    "    dth1 = f * (2 * p1 - 3 * np.cos(th1 - th2) * p2)\n",
    "    dth2 = f * (8 * p2 - 3 * np.cos(th1 - th2) * p1)\n",
    "\n",
    "    dp1  = - 0.5 * u1 * (  dth1 * dth2 * np.sin(th1 - th2) + 3 * u2 * np.sin(th1))\n",
    "    dp2  = - 0.5 * u1 * (- dth1 * dth2 * np.sin(th1 - th2) +     u2 * np.sin(th2))\n",
    "\n",
    "    return np.array([dth1, dth2, dp1, dp2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, atol in enumerate([1e-3,1e-6,1e-9,1e-12]):\n",
    "    T, X = DP45(f_dp, np.array([np.pi/2, np.pi/2, 0.0, 0.0]), 0, 10, 0.1, atol, 0)\n",
    "    plt.plot(T[::10], X[::10,0], '.-',  color=f'C{i}', label=f'atol={atol}')\n",
    "    plt.plot(T[::10], X[::10,1], '.--', color=f'C{i}')\n",
    "plt.legend()\n",
    "plt.xlabel('t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Adaptive time stepping is essential for problems that exhibit rapid, chaotic, or otherwise complex behavior.\n",
    "By continually adjusting the step size, $\\Delta t$, we ensure numerical errors remain under control while avoiding unnecessary computational overhead.\n",
    "This strategy proves especially beneficial for highly sensitive systems, where even slight changes in time steps can have dramatic effects on the calculated trajectory.\n",
    "\n",
    "Embedded Runge–Kutta methods, such as the Dormand–Prince (DP) family, are particularly well-suited for adaptive stepping.\n",
    "They produce multiple estimates of different orders within a single step, with the difference between these estimates serving as a direct measurement of local truncation error.\n",
    "Error control mechanisms, like the proportional–integral (PI) controller, dynamically adjust the step size based on these estimates, balancing accuracy and efficiency.\n",
    "To handle a wide range of solution magnitudes, we combine absolute and relative tolerances to form the error threshold.\n",
    "\n",
    "Although there are methods like Richardson extrapolation that can formally boost the order of accuracy, embedded Runge–Kutta formulas remain the primary choice for practical error estimation.\n",
    "By default, many established software libraries (including MATLAB's `ode45`) rely on embedded DP methods for their robust performance and favorable trade-off between cost and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Lagrangian Mechanics and the Euler-Lagrange Equation\n",
    "\n",
    "Classical mechanics can be formulated in multiple ways:\n",
    "1. Newton's Laws (force-based),\n",
    "2. Lagrangian Mechanics (action-based),\n",
    "3. Hamiltonian Mechanics (energy-based).\n",
    "\n",
    "In this section, we focus on Lagrangian mechanics, a powerful approach that simplifies problem solving.\n",
    "It is the foundation of many areas of modern physics, from elementary particle physics to general relativity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### The Principle of Least Action\n",
    "\n",
    "The idea of an \"action principle\" can be traced back to the 17th and 18th centuries.\n",
    "Early forms appeared in the work of Pierre de Fermat on the path taken by light (Fermat's principle of least time) and in Gottfried Wilhelm Leibniz's notions of optimality and geometry.\n",
    "By the mid-18th century, mathematicians and physicists such as Pierre Louis Maupertuis, Leonhard Euler, and Joseph-Louis Lagrange had generalized these ideas into what is now called the Principle of Least Action (or more accurately, the \"Principle of Stationary Action\").\n",
    "\n",
    "The key philosophical shift was recognizing that nature can often be described as if it \"chooses\" a path or configuration that makes some quantity---called the action---stationary (usually a minimum, but more precisely an extremum) with respect to small variations of the trajectory.\n",
    "This viewpoint was revolutionary because it reframed the laws of motion away from cause-and-effect forces (Newton's laws) and toward an elegant variational principle.\n",
    "\n",
    "Veritasium has an amazing video on the [principle of action](https://youtu.be/Q10_srZ-pbs) that covers both historical and mathematical/physical significance of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "We denote the action $S$ of a mechanical system moving between times $t_1$ and $t_2$ as an integral over a function called the Lagrangian $L$:\n",
    "\\begin{align}\n",
    "S[\\mathbf{q}] = \\int_{t_1}^{t_2} L\\left(\\mathbf{q}(t), \\dot{\\mathbf{q}}(t), t\\right)dt,\n",
    "\\end{align}\n",
    "where:\n",
    "* $\\mathbf{q}(t)$ represents the generalized coordinates of the system (e.g., angles, positions in space, etc.).\n",
    "* $\\dot{\\mathbf{q}}(t) = \\frac{d}{dt}\\mathbf{q}(t)$ denotes the time derivatives of these coordinates.\n",
    "* $L(\\mathbf{q}, \\dot{\\mathbf{q}}, t)$ is often written as $T - V$, the kinetic energy $T$ minus the potential energy $V$, for many standard physical systems.\n",
    "\n",
    "This integral of the Lagrangian over time is a single scalar number that characterizes the entire path $\\mathbf{q}(t)$ taken by the system between $t_1$ and $t_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Hamilton's Principle (or the Principle of Least Action) states that the actual trajectory $\\mathbf{q}(t)$ followed by a physical system makes the action $S[\\mathbf{q}]$ stationary with respect to small variations of the path.\n",
    "Symbolically, if we perturb the coordinates by a tiny amount $\\delta\\mathbf{q}(t)$, the first-order change in the action $\\delta S$ must vanish:\n",
    "\\begin{align}\n",
    "\\delta S = \\delta \\int_{t_1}^{t_2} L(\\mathbf{q}, \\dot{\\mathbf{q}}, t) dt = 0.\n",
    "\\end{align}\n",
    "It is important to note that \"stationary\" means the action could be a minimum, a maximum, or even a saddle point in function space.\n",
    "Nevertheless, it is historically called the \"Principle of Least Action,\" reflecting many common systems in which the solution does indeed minimize $S$.\n",
    "The rigorous requirement is that the action cannot be lowered by an infinitesimal variation of the physical path, which is what $\\delta S = 0$ encodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### The Euler-Lagrange Equation\n",
    "\n",
    "The Euler-Lagrange equation is the probably the most important result of Lagrangian mechanics.\n",
    "It directly follows from the Principle of Least Action.\n",
    "Once derived, it provides a systematic way to obtain the equations of motion in generalized coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "We write:\n",
    "\\begin{align}\n",
    "\\delta S = \\delta \\int_{t_1}^{t_2} L\\left(q,\\dot{q},t\\right) dt.\n",
    "\\end{align}\n",
    "\n",
    "Because $S$ is an integral, we can bring the variation inside:\n",
    "\\begin{align}\n",
    "\\delta S = \\int_{t_1}^{t_2} \\delta L\\left(q,\\dot{q},t\\right) dt.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Next, we expand the variation $\\delta L$ in terms of $\\delta q$ and $\\delta \\dot{q}$:\n",
    "\\begin{align}\n",
    "\\delta L\n",
    "= \\frac{\\partial L}{\\partial q} \\delta q\n",
    "+ \\frac{\\partial L}{\\partial \\dot{q}} \\delta\\dot{q}\n",
    "+ \\frac{\\partial L}{\\partial t} \\delta t.\n",
    "\\end{align}\n",
    "\n",
    "Since $t$ is our independent variable and is not itself being varied, the last term is typically omitted.\n",
    "Thus:\n",
    "\\begin{align}\n",
    "\\delta S = \\int_{t_1}^{t_2} \\left(\n",
    "  \\frac{\\partial L}{\\partial q}\\,\\delta q\n",
    "+ \\frac{\\partial L}{\\partial \\dot{q}}\\,\\delta \\dot{q}\n",
    "\\right) dt.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "The term $(\\partial L/\\partial \\dot{q})\\delta \\dot{q}$ can be converted into a function of $\\delta q$ by using integration by parts.\n",
    "In one dimension:\n",
    "\\begin{align}\n",
    "\\int_{t_1}^{t_2} \\frac{\\partial L}{\\partial \\dot{q}}\\,\\delta \\dot{q}\\,dt\n",
    "= \\left[\\frac{\\partial L}{\\partial \\dot{q}} \\delta q \\right]_{t_1}^{t_2}\n",
    "- \\int_{t_1}^{t_2} \\frac{d}{dt}\\Bigl(\\frac{\\partial L}{\\partial \\dot{q}}\\Bigr)\\delta q dt.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Since $\\delta q(t_1) = \\delta q(t_2) = 0$ by the boundary conditions, the boundary term\n",
    "\\begin{align}\n",
    "\\left[\\frac{\\partial L}{\\partial \\dot{q}}\\,\\delta q\\right]_{t_1}^{t_2}.\n",
    "\\end{align}\n",
    "vanishes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Thus, the variation of the action becomes:\n",
    "\\begin{align}\n",
    "\\delta S \n",
    "&= \\int_{t_1}^{t_2} \\left[\n",
    "\\frac{\\partial L}{\\partial q} -\n",
    "\\frac{d}{dt}\\Bigl(\\frac{\\partial L}{\\partial \\dot{q}}\\Bigr)\\right] \\delta q\\,dt.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The principle of stationary action states $\\delta S = 0$ for all permissible $\\delta q(t)$.\n",
    "Since $\\delta q(t)$ is an arbitrary small variation (other than being zero at the endpoints), the only way for the integral $\\delta S = 0$ to hold for every possible $\\delta q(t)$ is for the integrand itself to vanish identically:\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial q} - \\frac{d}{dt}\\Bigl(\\frac{\\partial L}{\\partial \\dot{q}}\\Bigr) = 0.\n",
    "\\end{align}\n",
    "This is the Euler-Lagrange equation for the single coordinate $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# Computational Lagrangian Mechanics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Having the Euler–Lagrange equation allows us to write down the equations of motion for any system given its Lagrangian.\n",
    "Based on what we've learned from this class, we convert each second-order Euler–Lagrange equation into two first-order ODEs in time (for $q_i$ and $\\dot{q}_i$).\n",
    "These can then be integrated with standard ODE solvers (e.g., Runge–Kutta and PD45 methods).\n",
    "Here, we will see how to automate the derivation of these equations using automatic differentiation (autodiff) and then solve them numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "To cast the Euler-Lagrange equation into a form that we can use with an ODE integrator, let $x = q$ and $v = \\dot{q}$.\n",
    "The Euler-Lagrange equation becomes:\n",
    "\\begin{align}\n",
    "  \\frac{d}{dt}\\left(\\frac{\\partial L}{\\partial v}\\right) &= \\frac{\\partial L}{\\partial x} \\\\\n",
    "  \\frac{\\partial^2 L}{\\partial v^2} \\dot{v} + \\frac{\\partial^2 L}{\\partial x\\partial v} \\dot{x} &= \\frac{\\partial L}{\\partial x} \\\\\n",
    "\\end{align}\n",
    "Let $a = \\dot{v}$ and rearrange,\n",
    "\\begin{align}\n",
    "  \\frac{\\partial^2 L}{\\partial v^2} a &= \\frac{\\partial L}{\\partial x} - \\frac{\\partial^2 L}{\\partial x\\partial v} v \\\\\n",
    "  a &= \\left(\\frac{\\partial^2 L}{\\partial v^2}\\right)^{-1} \\left(\\frac{\\partial L}{\\partial x} - \\frac{\\partial^2 L}{\\partial x\\partial v} v\\right)\n",
    "\\end{align}\n",
    "This last equation is exactly what we can put into an ODE integrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad, jacfwd, jit\n",
    "from jax.numpy.linalg import inv\n",
    "\n",
    "def ELrhs(L):\n",
    "    \n",
    "    Lx  = grad(L, argnums=0) # dL/dx\n",
    "    Lv  = grad(L, argnums=1) # dL/dv\n",
    "    Lvp = jacfwd(Lv, argnums=(0,1)) # -> d(dL/dv)/dx, d(dL/dv)/dv\n",
    "\n",
    "    @jit\n",
    "    def rhs(xv): # closure on Lx, Lv, Lvp, which are all functions\n",
    "        x,   v   = xv\n",
    "        Lvx, Lvv = Lvp(x, v)\n",
    "        a = inv(Lvv) @ (Lx(x, v) - v @ Lvx)\n",
    "        return np.array([v, a])\n",
    "\n",
    "    return rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path(L, xv0, t0, t1, dt=0.1, atol=1e-6, rtol=1e-6):\n",
    "    rhs = ELrhs(L)\n",
    "    return DP45(rhs, xv0, t0, t1, dt, atol, rtol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Example Applications\n",
    "\n",
    "We can now apply `path()` to solve a multi-dimensional simple harmonic oscillator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L(x, v):\n",
    "    return np.sum(0.5 * v * v - 0.5 * x * x) # (1/)2 v^2 - (1/2) x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "xv0   = np.array([[0.0,1.0], [1.0,0.0]])\n",
    "T, XV = path(L, xv0, 0.0, 2 * np.pi)\n",
    "\n",
    "X = XV[:,0,:]\n",
    "V = XV[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(T, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "We started with the Lagrangian viewpoint of classical mechanics, where each system is described by its kinetic and potential energies.\n",
    "Instead of directly applying Newton's laws, we use the principle of least action to determine how a system evolves in time.\n",
    "This approach not only simplifies the treatment of constraints and complex coordinate systems but also unifies a wide range of physical problems under a single conceptual framework.\n",
    "\n",
    "The next step involved translating our Lagrangian-based description into a concrete numerical procedure.\n",
    "Perhaps the most exciting part of our workflow is the use of automatic differentiation (autodiff).\n",
    "Rather than manually computing partial derivatives, we let autodiff tools do the heavy lifting.\n",
    "By defining the Lagrangian in code, we automatically generate the required derivatives and then form the corresponding equations of motion on the fly.\n",
    "This reduces the overhead of dealing with algebraic details, freeing us to focus on modeling and exploration.\n",
    "\n",
    "Finally, we combined these pieces into a Computational Lagrangian Mechanics solver.\n",
    "To the best of my knowledge, this streamlined toolchain is not found in standard Python libraries.\n",
    "This showcases how creatively leveraging existing numerical methods can push us to the cutting edge of computational physics!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
