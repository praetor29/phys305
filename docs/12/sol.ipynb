{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Bayesian Statistics Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "In this hands-on lab, we continue our demonstration of \"estimating the mass of a new fundamental particle\".\n",
    "We will generate multiple experiments, each giving a noisy measurement of the particle's mass, and sequentially update our posterior distribution after each experiment.\n",
    "We will then discuss what we should do when new theoretical prior appears."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Physical Setup (Brief Recap)\n",
    "\n",
    "Let's update some notation from the notes.\n",
    "\n",
    "We have a particle of **true mass** $m_\\text{true}$, measured in TeV.\n",
    "Each experiment yields an observed mass $m_\\text{obs}$ with Gaussian noise:\n",
    "\\begin{align}\n",
    "m_\\text{obs} \\;\\sim\\; \\mathcal{N}(m_\\text{true},\\sigma_\\text{expr}^2).\n",
    "\\end{align}\n",
    "Here, $\\sigma_\\text{expr}$ is the detector resolution or statistical uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "We know that $m_\\text{true}$ lies in some range $[2,8]$ TeV---our *initial theory* suggests it cannot be outside this window.\n",
    "Hence, our **initial prior**:\n",
    "\\begin{align}\n",
    "p(\\theta) = \n",
    "\\begin{cases}\n",
    "1/(8 - 2), & 2 \\le \\theta \\le 8, \\\\\n",
    "0, & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Each measurement modifies our belief (the prior) into a **posterior** via Bayes' Theorem:\n",
    "\\begin{align}\n",
    "p(m \\mid m_{\\text{obs}}) \\propto p(m_{\\text{obs}} \\mid m) \\, p(m).\n",
    "\\end{align}\n",
    "\n",
    "Here, the **likelihood** $p(m_\\text{obs} \\mid m_\\text{true})$ is given by the Gaussian formula:\n",
    "\\begin{align}\n",
    "p(m_{\\text{obs}} \\mid m) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_\\text{expr}} \\exp\\left[-\\frac{(m_{\\text{obs}}-m)^2}{2\\sigma_\\text{expr}^2}\\right].\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Single Experiment Code (Grid Approximation)\n",
    "\n",
    "Please rewrite the code in the class note into multiple functions that we can perform numerical experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: Define range for m (0 to 10 TeV)\n",
    "ms = np.linspace(0, 10, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: Gaussian likelihood\n",
    "def likelihood(x, x0, sigma):\n",
    "    norm = 1.0 / (np.sqrt(2*np.pi) * sigma)\n",
    "    return norm * np.exp(-0.5 * ((x-x0) / sigma)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_expr(\n",
    "    prior,        # Prior before updated by the experiment\n",
    "    m_true,       # Suppose this is the true mass\n",
    "    sigma_expr,   # Detector resolution\n",
    "    seed = None,  # For reproducibility\n",
    "):\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # HANDSON: By running an experiment, we obtain a single measurement\n",
    "    # You may use np.random.normal().\n",
    "    m_obs = np.random.normal(loc=m_true, scale=sigma_expr)\n",
    "    \n",
    "    # HANDSON: Posterior ~ prior * likelihood\n",
    "    like = likelihood(m_obs, ms, sigma_expr)\n",
    "    unnorm_post = like * prior\n",
    "\n",
    "    # HANDSON: Normalize the posterior\n",
    "    norm = 1 / np.trapezoid(unnorm_post, ms)\n",
    "    post = norm * unnorm_post\n",
    "\n",
    "    return m_obs, post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform prior in [2, 8]\n",
    "def prior0(ms, m_min=2, m_max=8):\n",
    "    # HANDSON: Uniform in [2,8], zero outside\n",
    "    return np.where((m_min <= ms) & (ms <= m_max), 1/(m_max-m_min), 0)\n",
    "\n",
    "# Compute prior\n",
    "prior = prior0(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a numerical experiment\n",
    "m_true     = 3.6  # Set the groundtruth\n",
    "sigma_expr = 1.0  # Detector resolution\n",
    "\n",
    "m_obs, post = run_expr(prior, m_true, sigma_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axvline(m_true, ls=':',  color='k',  label=r\"$m_\\text{true}=\"+f\"{m_true:.3f}$TeV\")\n",
    "plt.axvline(m_obs,  ls='--', color='C1', label=r\"$m_\\text{obs}= \"+f\"{m_obs:.3f}$TeV\")\n",
    "plt.plot(ms, post, 'k', label=\"Posterior (1 experiment)\")\n",
    "plt.title(\"Posterior after a single measurement\")\n",
    "plt.xlabel(\"Mass (TeV)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Multiple Experiments\n",
    "\n",
    "Now we simulate $N$ experiments. Each experiment provides $(m_{\\text{obs},i}, \\sigma_i) = (m_{\\text{obs},i}, \\sigma_\\text{expr})$.\n",
    "We update our posterior step by step:\n",
    "1. Start with the prior (initially uniform in $[2,8]$).\n",
    "2. For each experiment $i$, multiply the current posterior by the new likelihood.\n",
    "3. Normalize to get the updated posterior, which becomes the prior for the next experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: Let's simulate multiple experiments\n",
    "m_true     = 1.5  # Set the groundtruth\n",
    "sigma_expr = 1.0  # Detector resolution\n",
    "N          = 100  # Number of experiments\n",
    "\n",
    "ms_obs = np.random.normal(m_true, sigma_expr, N) # Draw N samples from a normal distribution.  You may use np.random.normal().\n",
    "\n",
    "print(\"Simulated experiment results:\")\n",
    "for i, m_obs in enumerate(ms_obs):\n",
    "    print(f\"\\tExperiment {i+1}: observed mass = {m_obs:.3f} Â± {sigma_expr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON: compute the prior from prior0()\n",
    "\n",
    "prior = prior0(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sequential Bayesian updates using the same grid approach\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.axvline(m_true, color='k', ls=':', label=r'$m_\\text{true}$')\n",
    "plt.plot(ms, prior, label=\"Initial Prior\", lw=2)\n",
    "\n",
    "for i, m_obs in enumerate(ms_obs):\n",
    "    # HANDSON: compute the posterior\n",
    "    m_obs, post = run_expr(prior, m_true, sigma_expr)\n",
    "\n",
    "    # Plot the posterior\n",
    "    if i % 20 == 19:\n",
    "        plt.plot(ms, post, label=f\"Posterior after Exp {i+1}\")\n",
    "\n",
    "    # HANDSON: posterior becomes prior for next iteration\n",
    "    prior = post\n",
    "\n",
    "plt.title(\"Sequential Bayesian Updates of Particle Mass\")\n",
    "plt.xlabel(\"Mass (TeV)\")\n",
    "plt.ylabel(\"Probability Density\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "You will see each new experiment narrowing or shifting the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON:\n",
    "# Try to increase `N` to, e.g, 100 and plot the posterior every 10 experiments.\n",
    "# What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON:\n",
    "# Try to change `m_true` to a value outside the theory, e.g., 1.5, and plot the posterior.\n",
    "# What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDSON:\n",
    "# Suppose now there are two theories, one suggests the mass range [2,8] TeV,\n",
    "# one suggests the mass range [1,5] TeV.\n",
    "# How would you take this new theory into account?\n",
    "# Try implement your idea(s) and interpret the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
