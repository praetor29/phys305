{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Modeling II: Bayesian Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Bayesian statistics systematically combines our prior knowledge about a situation with new data to refine what we believe is true.\n",
    "In countless real-world scenarios---ranging from medical diagnostics to fundamental physics experiments---information we already have (like the rarity of a disease or theoretical constraints on a physical parameter) can significantly shape how we interpret fresh evidence.\n",
    "By framing unknowns as probability distributions, Bayesian methods provide a coherent framework for updating those distributions whenever new observations appear, yielding a posterior that reflects all evidence, old and new.\n",
    "This unifying perspective makes it possible to quantify uncertainties in a transparent way, avoid common logical pitfalls, and naturally propagate errors to any derived quantities of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Medical Test \"Paradox\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "The medical test paradox occurs when a diagnostic test is described as highly accurate, yet a person who tests positive for a rare disease ends up with a much lower chance of actually having it.\n",
    "This seemingly contradiction highlights the importance of prior knowledge or base rates.\n",
    "\n",
    "Consider a disease that affects only 1% of the population.\n",
    "Imagine a test that has:\n",
    "* 99% sensitivity: if you **do** have the disease, it flags you positive 99% of the time.\n",
    "* 99% specificity: if you **do not** have the disease, it correctly flags you negative 99% of the time.\n",
    "\n",
    "Many people assume that a \"99% accurate\" test implies a 99% chance of having the disease if you test positive.\n",
    "We will see that is not necessarily true when the disease is rare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### A Simple Counting Argument\n",
    "\n",
    "Suppose we have 10,000 people.\n",
    "About 100 of them are diseased (1%).\n",
    "The remaining 9,900 are healthy.  \n",
    "\n",
    "Of the 100 diseased people, 99 will test positive (true positives).\n",
    "Of the 9,900 healthy people, 1% will falsely test positive (99 people).\n",
    "We end up with a total of 198 positive results: 99 true positives plus 99 false positives.\n",
    "\n",
    "Hence, only half of these positives (99 out of 198) are truly diseased.\n",
    "This implies a 50% chance of actually having the disease, which is far lower than 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Why This Happens\n",
    "\n",
    "When a condition is rare, most people do not have it.\n",
    "A small fraction of a large healthy group (the 1% false-positive rate applied to 9,900 healthy people) can match or exceed the positives from the much smaller diseased group.\n",
    "This is a direct consequence of prior probability: we have to weigh how common the disease is before we interpret a new test result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## An Intuitive Derivation of Bayes' Theorem\n",
    "\n",
    "Bayes' Theorem emerges directly from the definition of **conditional probability**.\n",
    "We start with $P(A \\mid B)$, which is read as \"the probability of $A$ given that $B$ occurred.\"\n",
    "By definition, this is the fraction of times both $A$ and $B$ happen, out of all times $B$ happens:\n",
    "\\begin{align}\n",
    "P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Here, $P(A \\cap B)$ is the joint probability that both events occur.\n",
    "We can also express this joint probability in another way:\n",
    "\\begin{align}\n",
    "P(A \\cap B) = P(B \\mid A)\\,P(A).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Placing this back into our conditional probability formula gives:\n",
    "\\begin{align}\n",
    "P(A \\mid B)\n",
    "= \\frac{P(B \\mid A)\\,P(A)}{P(B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We can split $B$ into two disjoint groups:\n",
    "\\begin{align}\n",
    "P(B) = P(B \\mid A)\\,P(A) \\;+\\; P(B \\mid \\bar{A})\\,P(\\bar{A}).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Putting this altogether yields **Bayes' Theorem**:\n",
    "\\begin{align}\n",
    "P(A \\mid B)\n",
    "= \\frac{P(B \\mid A)\\,P(A)}\n",
    "       {P(B \\mid A)\\,P(A) \\;+\\; P(B \\mid \\bar{A})\\,P(\\bar{A})}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "We can connect each term to our **medical test paradox**. In that story:\n",
    "* $P(A)$ is the **prevalence** (1%).\n",
    "* $P(\\bar{A})$ is the chance of not having the disease (99%).\n",
    "* $P(B \\mid A)$ is the **sensitivity** (99%).\n",
    "* $P(B \\mid \\bar{A})$ is the **false-positive rate** (1%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "When we substitute these numbers, we match the counting argument that led to a final probability of around 50% if you test positive.\n",
    "This result might seem surprising at first, but it follows naturally once we include both the **base rate** of the disease and the test's **accuracy**.\n",
    "Bayes' Theorem thus formalizes the intuition behind \"counting true positives vs. false positives\" and ensures we do not overlook the large fraction of healthy individuals in the population."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "This same line of reasoning applies to many physics and data-modeling scenarios.\n",
    "We often start with a **prior** for a parameter (like the prevalence in the medical example) and then update it with **likelihood** information from new observations.\n",
    "Bayes' Theorem tells us how to combine both pieces of information in a consistent way, yielding a **posterior probability** that captures our updated understanding of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Why Bayes' Theorem Matters\n",
    "\n",
    "The key power of Bayes' Theorem is that it forces us to incorporate the **prior probability** $P(A)$ before we look at new evidence $B$.\n",
    "Once the data (test results) come in, we use the likelihood $P(B \\mid A)$ to update this prior, producing the **posterior probability** $P(A \\mid B)$.\n",
    "In the medical context, the \"update\" reveals how a single test result against a low prevalence might not be enough for a confident diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## A Physically Motivated Example: Exoplanet Detection\n",
    "\n",
    "We can adapt the logic from the medical test paradox to a physics or astronomy problem.\n",
    "Consider exoplanet detection: we look for a slight dip in a star's brightness that could signify a planet passing in front of the star (a \"transit\").\n",
    "Even if our detection algorithm is \"99% accurate,\" it may trigger many **false alarms** due to noise or stellar variability.\n",
    "If only a small fraction of stars have detectable planets, we face a scenario similar to the medical test paradox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setup\n",
    "\n",
    "1. **Prevalence (Prior):** Suppose only **1%** of stars in our survey have a planet large enough (and orbit aligned just right) to cause a detectable transit.\n",
    "2. **Detection Sensitivity:** If a star truly has a planet, our detection pipeline correctly flags it **99%** of the time.\n",
    "3. **False Alarm Rate:** If a star does **not** have a planet, the pipeline still flags a **false positive** **1%** of the time (perhaps due to random noise, starspots, or measurement artifacts).\n",
    "\n",
    "These numbers mirror the \"disease prevalence\" and \"test sensitivity\" from the medical example.\n",
    "We want to know the **posterior probability** that a star truly has a planet given that we have detected a \"transit signal.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Bayes' Theorem for Exoplanets\n",
    "\n",
    "Let:\n",
    "* $A$ = \"Star has a detectable planet.\"\n",
    "* $B$ = \"Detection algorithm flags a transit.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "By Bayes' Theorem,\n",
    "\\begin{align}\n",
    "P(\\text{Star has planet} \\,\\mid\\, \\text{Transit Flag}) =\n",
    "\\frac{P(\\text{Transit Flag} \\,\\mid\\, \\text{Star has planet}) \\times P(\\text{Star has planet})}{P(\\text{Transit Flag})}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "Here:\n",
    "1. $P(\\text{Star has planet})$ is the 1% prevalence (prior).\n",
    "2. $P(\\text{Transit Flag} \\,\\mid\\, \\text{Star has planet})$ is the 99% detection sensitivity.\n",
    "3. $P(\\text{Transit Flag})$ accounts for both real transits and false alarms.\n",
    "\n",
    "Just like in the medical paradox, we expect the **posterior probability** of having a planet given a positive detection to be around **50%**, not 99%. The rarity (1% prevalence) dilutes the significance of a single positive detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of stars in the survey\n",
    "N_stars = 100_000\n",
    "\n",
    "# Prior: fraction of stars with a detectably transiting planet\n",
    "planet_prevalence = 0.01\n",
    "\n",
    "# Detection sensitivity: P(flagged transit | planet)\n",
    "detection_sensitivity = 0.99\n",
    "\n",
    "# False alarm rate: P(flagged transit | no planet) = 1 - specificity\n",
    "false_alarm_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "# Simulate which stars have planets\n",
    "stars_have_planet = [\n",
    "    random() < planet_prevalence\n",
    "    for _ in range(N_stars)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate detection outcomes\n",
    "flags = []\n",
    "for has_planet in stars_have_planet:\n",
    "    if has_planet:\n",
    "        # Real transit flagged with probability = detection_sensitivity\n",
    "        flag = random() < detection_sensitivity\n",
    "    else:\n",
    "        # False alarm with probability = false_alarm_rate\n",
    "        flag = random() < false_alarm_rate\n",
    "    flags.append(flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many flagged\n",
    "flagged_count = sum(flags)\n",
    "\n",
    "# Count how many flagged stars actually have planets\n",
    "true_planet_count = sum(\n",
    "    has_planet and flagged \n",
    "    for has_planet, flagged in zip(stars_have_planet, flags)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Out of {N_stars} stars, {flagged_count} were flagged.\")\n",
    "if flagged_count > 0:\n",
    "    posterior_prob = true_planet_count / flagged_count\n",
    "    print(f\"Among flagged stars, {true_planet_count} truly have planets.\")\n",
    "    print(f\"Posterior probability of having a planet if flagged: \"\n",
    "          f\"{posterior_prob:.2f}\")\n",
    "else:\n",
    "    print(\"No transits flagged (very unlikely with these settings)!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    "Adjust the different parameters and check if the results follow your intuition.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## The Monty Hall Problem Through a Bayesian Lens\n",
    "\n",
    "The Monty Hall problem is a classic puzzle that highlights how new information can dramatically change our probabilities.\n",
    "Traditionally, you face three doors: one has a prize (car), the others have goats.\n",
    "You pick one door.\n",
    "Monty Hall, who knows where the prize is, then opens a different door that does not contain the prize.\n",
    "The question is: Should you switch to the remaining unopened door, or stick with your original choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "A Bayesian perspective clarifies why switching is advantageous.\n",
    "We start with a uniform prior: the probability that the prize is behind any given door is $1/3$.\n",
    "Once Monty opens a door that is guaranteed to reveal a goat (i.e., no prize), we update those prior probabilities into a posterior distribution that heavily favors the remaining door."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Prior Probabilities\n",
    "\n",
    "Label the doors $A, B, C$. Suppose you choose door $A$.\n",
    "Initially, there is a:\n",
    "* $1/3$ chance the prize is behind $A$.\n",
    "* $1/3$ chance the prize is behind $B$.\n",
    "* $1/3$ chance the prize is behind $C$.\n",
    "\n",
    "These are our **prior** probabilities.\n",
    "No extra information is known."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Likelihood of Monty\\end{align}s Action\n",
    "\n",
    "Monty will open a door (say door $B$ or $C$), revealing no prize.\n",
    "Monty knows where the prize is and **never** opens a door that has the prize.\n",
    "He also does **not** open your chosen door $A$.\n",
    "\n",
    "We define the event $M_B$ as \"Monty opens door $B$.\"\n",
    "From a Bayesian viewpoint, the likelihood $P(M_B \\mid \\text{Prize behind } X)$ is the probability that Monty opens $B$ **given** the actual location of the prize is $X$.\n",
    "For example:\n",
    "\n",
    "1. If the prize is behind $A$, Monty is **free** to open either $B$ or $C$ (each with 50% probability, because both are goats). So:\n",
    "   \\begin{align}\n",
    "   P(M_B \\mid \\text{prize behind } A) = \\frac{1}{2}.\n",
    "   \\end{align}\n",
    "\n",
    "2. If the prize is behind $B$, Monty **never** opens $B$. So:\n",
    "   \\begin{align}\n",
    "   P(M_B \\mid \\text{prize behind } B) = 0.\n",
    "   \\end{align}\n",
    "\n",
    "3. If the prize is behind $C$, Monty **must** open $B$, because $A$ is your choice and $C$ has the prize. So:\n",
    "   \\begin{align}\n",
    "   P(M_B \\mid \\text{prize behind } C) = 1.\n",
    "   \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Posterior Probability via Bayes' Theorem\n",
    "\n",
    "We observe $M_B$ (Monty opened door $B$), which shows a goat.\n",
    "We update the probability that the prize is behind either $A$ or $C$ using Bayes' Theorem.\n",
    "Let $X$ be the event \"Prize behind $X$.\"\n",
    "\\begin{align}\n",
    "P(\\text{prize behind } A \\mid M_B)\n",
    "= \\frac{P(M_B \\mid \\text{prize behind } A)\\, P(\\text{prize behind } A)}{P(M_B)}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Similarly for door $C$:\n",
    "\\begin{align}\n",
    "P(\\text{prize behind } C \\mid M_B)\n",
    "= \\frac{P(M_B \\mid \\text{prize behind } C)\\, P(\\text{prize behind } C)}{P(M_B)}.\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "We first compute $P(M_B)$ by summing over all ways Monty might open $B$:\n",
    "\\begin{align}\n",
    "P(M_B)\n",
    "= P(M_B \\mid \\text{prize behind } A)\\,P(\\text{prize behind } A)\n",
    "+ P(M_B \\mid \\text{prize behind } B)\\,P(\\text{prize behind } B)\n",
    "+ P(M_B \\mid \\text{prize behind } C)\\,P(\\text{prize behind } C).\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Substitute the known probabilities:\n",
    "\\begin{align}\n",
    "P(M_B) \n",
    "&= \\tfrac12 \\times \\tfrac13 + 0 \\times \\tfrac13 + 1 \\times \\tfrac13 \\\\\n",
    "&= \\tfrac{1}{6} + 0 + \\tfrac{1}{3} \n",
    "= \\tfrac{1}{6} + \\tfrac{2}{6}\n",
    "= \\tfrac{3}{6}\n",
    "= \\tfrac12.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Now plug back into Bayes' formula:\n",
    "\n",
    "\\begin{align}\n",
    "P(\\text{prize behind } A \\mid M_B)\n",
    "&= \\frac{\\tfrac12 \\times \\tfrac13}{\\tfrac12}\n",
    "= \\frac{\\tfrac{1}{6}}{\\tfrac12}\n",
    "= \\frac{1}{3} \\\\\n",
    "P(\\text{prize behind } C \\mid M_B)\n",
    "&= \\frac{1 \\times \\tfrac13}{\\tfrac12}\n",
    "= \\frac{\\tfrac{1}{3}}{\\tfrac12}\n",
    "= \\frac{2}{3}.\n",
    "\\end{align}\n",
    "\n",
    "So, given that Monty opened $B$, the probability the prize lies behind $A$ remains **$1/3$**, while the probability it lies behind $C$ rises to $2/3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### Outcome: Switching is Better\n",
    "\n",
    "The Bayesian calculation shows that, after Monty opens a non-prize door $B$, door $C$ now carries twice the probability of having the car ($2/3$) compared to door $A$ ($1/3$).\n",
    "Bayesian reasoning makes the role of Monty's knowledge and purposeful action explicit: his choice to reveal a goat is *not* random and thus modifies your posterior probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "N = 100_000\n",
    "switch_wins = 0\n",
    "\n",
    "for _ in range(N):\n",
    "    # Randomly choose the door with the prize\n",
    "    prize_door = choice(['A','B','C'])\n",
    "    # You pick door A\n",
    "    your_choice = 'A'\n",
    "    \n",
    "    # Monty opens a door that has a goat and isn't your choice\n",
    "    # Let's see which doors are available to Monty\n",
    "    doors_left_for_monty = ['A','B','C']\n",
    "    doors_left_for_monty.remove(your_choice)\n",
    "    \n",
    "    # He won't open the prize door\n",
    "    if prize_door in doors_left_for_monty:\n",
    "        doors_left_for_monty.remove(prize_door)\n",
    "    \n",
    "    # Now Monty picks randomly from the remaining goats if more than one is possible\n",
    "    monty_opens = choice(doors_left_for_monty)\n",
    "    \n",
    "    # The other unopened door after Monty is:\n",
    "    doors_unopened = ['A','B','C']\n",
    "    doors_unopened.remove(your_choice)\n",
    "    doors_unopened.remove(monty_opens)\n",
    "    \n",
    "    # This is the door you'd switch to\n",
    "    switched_door = doors_unopened[0]\n",
    "    \n",
    "    # Check if switching wins\n",
    "    if switched_door == prize_door:\n",
    "        switch_wins += 1\n",
    "\n",
    "print(f\"Switching success rate: {switch_wins / N:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Why Bayesian Reasoning Helps\n",
    "\n",
    "In the Monty Hall puzzle, Monty's knowledge is crucial.\n",
    "He does not randomly open a door; he always opens a door with a goat.\n",
    "Bayesian updates naturally encode the fact that Monty's behavior provides you information.\n",
    "If Monty had opened a door randomly and happened to reveal a goat, that would yield a very different likelihood function and hence a different posterior.\n",
    "But given Monty's consistent, informed strategy, the posterior probability shifts from $(1/3,1/3,1/3)$ to $(1/3, 0, 2/3)$ for $(A, B, C)$ once door $B$ is shown to have no prize.\n",
    "\n",
    "By showing how the prior (1/3 for each door) is updated by Monty's action (likelihood depends on where the prize is and which door he opens), Bayes' Theorem makes the final distribution (1/3 vs. 2/3) transparent.\n",
    "This is precisely the essence of Bayesian inference: we begin with uniform probabilities, incorporate new evidence, and end up with a posterior distribution that strongly favors the door Monty did not open."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    "What happens if we increse the number of doors to $N$, and Monty Hall still opens one door with a goat?\n",
    "Should we switch in such a case?\n",
    "What is the winning probability if we switch?\n",
    "\n",
    "What happens if we increse the number of doors to $N$, and Monty Hall opens $N-2$ door with a goat?\n",
    "Should we switch in such a case?\n",
    "What is the winning probability if we switch?\n",
    "\n",
    "You may think through this, or modify the above code to simulate it.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "## Example: Estimating the Mass of a New Fundamental Particle\n",
    "\n",
    "In high-energy physics, discovering or characterizing a new particle often boils down to measuring its mass (alongside other properties like spin or decay channels).\n",
    "Particle masses are typically extracted from observed signatures in a detector, such as energy peaks or invariant-mass distributions of decay products.\n",
    "Bayesian methods are increasingly used to combine \"priors\" (e.g., theoretical constraints, previous measurments) with \"likelihood\" (collision data) to infer a posterior distribution for the unknown mass.\n",
    "\n",
    "Below is a simplified illustration that mirrors our earlier continuous examples but sets the context in particle physics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Physical Picture\n",
    "\n",
    "Suppose theorists predict a new fundamental particle with a mass in the range of 2 to 5 TeV.\n",
    "We carry out an experiment in a large collider and measure an invariant mass peak from the particle's decay products.\n",
    "However, our measurement is noisy and uncertain due to detector resolution, background events, etc.\n",
    "Let:\n",
    "* $m_\\text{true}$ = the particle's (unknown) true mass (in TeV).\n",
    "* $m_\\text{obs}$ = the observed peak from our measurement (in TeV).\n",
    "\n",
    "We assume a **Gaussian** error model for simplicity:\n",
    "\\begin{align}\n",
    "m_{\\text{obs}} \\sim \\mathcal{N}(m_\\text{true}, \\sigma_\\text{expr}^2),\n",
    "\\end{align}\n",
    "where $\\sigma_\\text{expr}$ represents the *typical detector resolution* or *statistical uncertainty* in reconstructing the mass peak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Prior on the Particle's Mass\n",
    "\n",
    "We might have a **theoretical prior** stating that $m$ lies between 2 and 8 TeV, with no strong preference within that range.\n",
    "That leads to a **uniform prior**:\n",
    "\\begin{align}\n",
    "p(\\theta) = \n",
    "\\begin{cases}\n",
    "1/(8 - 2), & 2 \\le \\theta \\le 8, \\\\\n",
    "0, & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "In a real analysis, the prior might come from previous measurements/constraints like electroweak measurements or indirect searches, but a uniform prior is a straightforward starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### Likelihood of Observed Data\n",
    "\n",
    "If the measured peak is $m_\\text{obs}=3.6$ TeV with an uncertainty $\\sigma_\\text{expr}=1.0$ TeV, the **likelihood** function is:\n",
    "\\begin{align}\n",
    "p(m_{\\text{obs}} \\mid m) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_\\text{expr}} \\exp\\left[-\\frac{(m_{\\text{obs}}-m)^2}{2\\sigma_\\text{expr}^2}\\right].\n",
    "\\end{align}\n",
    "\n",
    "This function is large if $m$ is near 3.6 TeV and small if $m$ is far from 3.6 TeV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Posterior Distribution\n",
    "\n",
    "Bayes' Theorem states:\n",
    "\\begin{align}\n",
    "p(m \\mid m_{\\text{obs}}) \\propto p(m_{\\text{obs}} \\mid m) \\, p(m).\n",
    "\\end{align}\n",
    "\n",
    "We then normalize the right-hand side to ensure the posterior integrates to 1 over $m \\in [2,8]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Python Demo: Simple Grid Approximation\n",
    "\n",
    "Below is a small Python code that illustrates how to compute the posterior distribution by sampling $m$ on a grid from 2 to 8 TeV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observed mass peak (TeV) and estimated detector resolution (TeV)\n",
    "m_true     = 3.6\n",
    "m_obs      = 4.1  # doesn't have to be identical to m_true\n",
    "sigma_expr = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define range for m (0 to 10 TeV)\n",
    "ms = np.linspace(0, 10, 1001)\n",
    "\n",
    "# Uniform prior in [2, 8]\n",
    "def prior0(ms, m_min=2, m_max=8):\n",
    "    # Uniform in [2,8], zero outside\n",
    "    return np.where((m_min <= ms) & (ms <= m_max), 1/(m_max-m_min), 0)\n",
    "\n",
    "# Compute prior\n",
    "prior = prior0(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian likelihood\n",
    "def likelihood(x, x0, sigma):\n",
    "    norm = 1.0 / (np.sqrt(2*np.pi) * sigma)\n",
    "    return norm * np.exp(-0.5 * ((x-x0) / sigma)**2)\n",
    "\n",
    "# Compute likelihood\n",
    "like = likelihood(m_obs, ms, sigma_expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior ~ prior * likelihood\n",
    "\n",
    "unnorm_post = like * prior\n",
    "norm = 1 / np.trapezoid(unnorm_post, ms)\n",
    "post = norm * unnorm_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posterior\n",
    "\n",
    "plt.axvline(m_true, ls=':',  color='k',  label=r\"$m_\\text{true}=\"+f\"{m_true:.3f}$TeV\")\n",
    "plt.axvline(m_obs,  ls='--', color='C1', label=r\"$m_\\text{obs}= \"+f\"{m_obs:.3f}$TeV\")\n",
    "plt.plot(ms, post, label=\"Posterior PDF\")\n",
    "plt.xlabel(\"Mass (TeV)\")\n",
    "plt.ylabel(\"Posterior Density\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "When you run this script, you see a posterior distribution peaked near 4.1 TeV.\n",
    "The width of the posterior depends on $\\sigma_\\text{expr}$ and also how close 3.6 TeV is to the edges (2 or 8 TeV).\n",
    "If the measured value were near the boundary (e.g., 2.1 TeV), the posterior might be truncated heavily on one side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "In this simplified scenario:\n",
    "1. The prior indicates that $m$ should lie somewhere between 2 and 8 TeV.\n",
    "2. The likelihood becomes sharper if our detector resolution is good (small $\\sigma_\\text{expr}$).\n",
    "3. The posterior is effectively a constrained, \"truncated\" Gaussian centered near the observed peak, but strictly between 2 and 8 TeV.\n",
    "\n",
    "In reality, measuring a new particle mass typically involves many events rather than a single measurement.\n",
    "We would accumulate data from multiple collisions, each with some measured mass or energy distribution.\n",
    "The Bayesian approach, however, remains the same: start with a prior (theoretical constraints), define the likelihood (the probability of observing the data given a hypothesized mass), and compute the posterior distribution over $m$.\n",
    "(See the lab.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "```{exercise}\n",
    "Adjust the different parameters and check if the results follow your intuition.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## Error Propagation\n",
    "\n",
    "In many experiments, we want to determine **physical properties** that are not directly measurable.\n",
    "Instead, we rely on related **measured parameters** that each come with their own uncertainties.\n",
    "For example, in high‐energy or nuclear physics experiments, we might measure a particle's track curvature $c$ in a magnetic field $B$ together with velocity $v$, then use those data to infer the particle's **charge** $q$ and/or **mass** $m$.\n",
    "The measurements of curvature and velocity can be correlated, and each has its own uncertainty contribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "We often want to go further and compute **derived quantities** like the ratio $m/q$, the total energy $E \\approx mc^2$, or other combinations of $(m,q)$.\n",
    "Error propagation in these scenarios must carefully account for both the **magnitude** of each uncertainty and any **correlation** between parameters.\n",
    "\n",
    "In a **Bayesian** approach, once we have a **joint posterior** over $(m,q)$, pushing those uncertainties through any function $g(m,q)$ is straightforward: we evaluate $g$ at each posterior sample.\n",
    "This avoids the complexities of algebraic propagation or linearizing the function at a single point estimate, which can be challenging for strongly **nonlinear** relationships or highly **correlated** parameters.\n",
    "\n",
    "Below is a **toy example** demonstrating **two** practical methods for error propagation in a two-parameter setting:\n",
    "1. The **partial‐derivative (frequentist) approach** with a covariance matrix.\n",
    "2. The **Bayesian sampling approach**, which uses posterior samples (or any Monte Carlo sample) for $(m,q)$, directly yielding a distribution for $g(m,q)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "### Example Setup\n",
    "\n",
    "Let's imagine a particle in a magnetic field $B$.\n",
    "We measure:\n",
    "* **Track curvature** $c$ (with uncertainty $\\sigma_c$).\n",
    "* **Velocity** $v$ (with uncertainty $\\sigma_v$).\n",
    "\n",
    "We want to infer the **charge** $q$ and **mass** $m$ of the particle.\n",
    "A simplified relationship might be:\n",
    "\\begin{align}\n",
    "c = \\frac{q\\,B}{m\\,v},\n",
    "\\end{align}\n",
    "assuming a non‐relativistic regime.\n",
    "In a real experiment, multiple data points (and possibly more parameters) would be used, but we'll stick to a single observation to keep the demonstration concise.\n",
    "\n",
    "**Derived Quantity**: Suppose we're particularly interested in the ratio $m/q$.\n",
    "How do we **propagate** the uncertainties in $(m, q)$ into the uncertainty in $m/q$?\n",
    "We'll demonstrate two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "### Partial‐Derivative (Frequentist) Error Propagation\n",
    "\n",
    "If you already have **best‐fit values** $(m_0,q_0)$ and a **2×2 covariance matrix** $\\mathbf{C}$ for $(m,q)$, you can estimate the variance of any smooth function $g(m,q)$ via the familiar formula:\n",
    "\\begin{align}\n",
    "\\mathrm{Var}[g] \\approx\n",
    "\\nabla g\\bigl|_{\\!(m_0,q_0)} \\;\\mathbf{C}\\;\n",
    "(\\nabla g\\bigl|_{\\!(m_0,q_0)})^T,\n",
    "\\end{align}\n",
    "where $\\nabla g$ is the vector $\\bigl(\\tfrac{\\partial g}{\\partial m},\\,\\tfrac{\\partial g}{\\partial q}\\bigr)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "Let $g(m,q) = m/q$. Its partial derivatives at any $(m,q)$ are:\n",
    "\\begin{align}\n",
    "\\frac{\\partial g}{\\partial m} =\\frac{1}{q}, \n",
    "\\quad\n",
    "\\frac{\\partial g}{\\partial q} = -\\frac{m}{q^2}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "If $(m_0,q_0)$ is our best‐fit estimate, we evaluate those derivatives there.\n",
    "Then,\n",
    "\\begin{align}\n",
    "\\mathrm{Var}[g] =\n",
    "\\begin{pmatrix}\n",
    "\\tfrac{1}{q_0} & -\\tfrac{m_0}{q_0^2}\n",
    "\\end{pmatrix}\n",
    "\\mathbf{C}\n",
    "\\begin{pmatrix}\n",
    "\\tfrac{1}{q_0} \\\\\n",
    "-\\tfrac{m_0}{q_0^2}\n",
    "\\end{pmatrix}.\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose best-fit parameter estimates\n",
    "m0 = 5.0  # e.g. mass\n",
    "q0 = 1.0  # e.g. charge\n",
    "\n",
    "# Covariance matrix for (m, q)\n",
    "# var(m)=0.3, var(q)=0.09, cov(m,q)=-0.01 (just an example)\n",
    "cov_mq = np.array([\n",
    "    [0.3,   -0.002],\n",
    "    [-0.002, 0.007]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(m, q):\n",
    "    return m / q\n",
    "\n",
    "def dg_dm(m, q):\n",
    "    return 1.0 / q\n",
    "\n",
    "def dg_dq(m, q):\n",
    "    return -m / (q**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate partials at (m0, q0)\n",
    "dgdm_0 = dg_dm(m0, q0)\n",
    "dgdq_0 = dg_dq(m0, q0)\n",
    "grad_g = np.array([dgdm_0, dgdq_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance from the covariance formula\n",
    "var_g = grad_g @ cov_mq @ grad_g\n",
    "std_g = np.sqrt(var_g)\n",
    "g0    = g(m0, q0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Partial-Derivative Error Propagation:\")\n",
    "print(f\"Best-fit (m,q) = ({m0}, {q0}) => g(m,q)=m/q = {g0:.3f}\")\n",
    "print(f\"Propagated 1σ uncertainty in g: ±{std_g:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "### Bayesian/Monte Carlo Approach\n",
    "\n",
    "If you have posterior samples (from MCMC, for instance) or any method to draw random samples of $(m,q)$ consistent with their joint uncertainty, you can:\n",
    " 1. Sample $(m^{(s)},q^{(s)})$.\n",
    " 2. For each sample, compute $g^{(s)} = g(m^{(s)},q^{(s)})$.\n",
    " 3. Summarize the resulting distribution of ${g^{(s)}}$ to get the mean, standard deviation, credible interval, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "If your posterior is roughly 2D Gaussian, you can simulate from it by applying the Cholesky transform to a covariance matrix.\n",
    "The same logic extends to general posteriors from MCMC or a grid approximation.\n",
    "Below is code that uses the same $(m_0,q_0)$ and cov_mq but draws many correlated samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mq = np.array([m0, q0])\n",
    "L = np.linalg.cholesky(cov_mq)\n",
    "z = np.random.normal(size=(2,n_samples))  # uncorrelated draws\n",
    "mq_samples = (L @ z) + mean_mq.reshape(2,1)\n",
    "\n",
    "m_samples = mq_samples[0,:]\n",
    "q_samples = mq_samples[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the derived quantity g = m/q for each sample\n",
    "g_samples = m_samples / q_samples\n",
    "\n",
    "# Summaries\n",
    "g_mean_mc = g_samples.mean()\n",
    "g_std_mc  = g_samples.std(ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Monte Carlo/Bayesian Sampling\")\n",
    "print(f\"Mean of samples: {g_mean_mc:.3f}\")\n",
    "print(f\"Std  of samples: {g_std_mc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Plot the distribution of g\n",
    "plt.hist(g_samples, bins=100, density=True, alpha=0.5)\n",
    "plt.axvline(g_mean_mc, ls='--', color='C1', label=\"Mean\")\n",
    "plt.xlabel(\"g = m/q\")\n",
    "plt.ylabel(\"Density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "In a Bayesian workflow, you may already have $(m^{(s)},q^{(s)})$ from an MCMC chain or a 2D grid.\n",
    "You just plug them into $g(m,q)$ to get `g_samples`.\n",
    "The posterior distribution of $g$ emerges naturally, capturing any nonlinearities or correlations in the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### Comparing the Two Methods\n",
    "\n",
    "If the posterior for $(m,q)$ is nearly Gaussian and $g(m,q)$ is modestly linear in that region, both methods agree.\n",
    "But if the relationship is strongly nonlinear, or if the posterior is skewed or multimodal, the partial-derivative approach can give misleading results.\n",
    "The sampling approach handles these complexities seamlessly—provided you have a reliable set of parameter samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "1. **Small, Near-Gaussian Uncertainties**\n",
    "   The partial‐derivative approach is often fine.\n",
    "   It's straightforward when you already have a covariance matrix and the parameters aren't too large or correlated.\n",
    "2. **Nonlinear or Large Uncertainties**\n",
    "   Bayesian/Monte Carlo sampling is more robust.\n",
    "   You don't need to compute partial derivatives or assume linearity.\n",
    "   Any correlations or skewness in the posterior are automatically handled.\n",
    "3. **High‐Dimensional**\n",
    "   In multi-parameter problems, partial derivatives become cumbersome to manage, but sampling scales naturally (although MCMC can be computationally heavy).\n",
    "4. **Combining with Physical/Experimental Context**\n",
    "   If your experiment yields a joint distribution for $(m,q)$ from a proper Bayesian analysis, you already have posterior samples.\n",
    "   Computing derived uncertainties is then trivial: just apply the derived function to each sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
